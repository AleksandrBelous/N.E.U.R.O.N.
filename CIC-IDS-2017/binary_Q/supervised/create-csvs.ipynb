{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:09:48.669270Z",
     "start_time": "2025-03-03T17:09:48.418371Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:11:17.800821Z",
     "start_time": "2025-03-03T17:11:17.796089Z"
    }
   },
   "source": [
    "# Путь к папке с атаками\n",
    "base_path = \"../../distributions\"\n",
    "\n",
    "combined_path = \"./combined_csvs/\"\n",
    "os.makedirs(combined_path, exist_ok=True)\n",
    "\n",
    "distributions_folders = os.listdir(base_path)\n",
    "distro_labels = { attack: idx + 1 for idx, attack in enumerate(distributions_folders) }\n",
    "distro_labels"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cauchy': 1, 'exponential': 2, 'normal': 3, 'gamma': 4}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-03T17:11:19.207516Z",
     "start_time": "2025-03-03T17:11:19.203308Z"
    }
   },
   "source": [
    "# Найти все уникальные размеры выборок\n",
    "packet_intervals = set()\n",
    "\n",
    "for distro in distributions_folders:\n",
    "    common_path = os.path.join(base_path, distro, \"csvs\")\n",
    "    # print(common_path)\n",
    "    # ../../distributions/cauchy/csvs\n",
    "    # ../../distributions/exponential/csvs\n",
    "    # ../../distributions/normal/csvs\n",
    "    # ../../distributions/gamma/csvs\n",
    "    for traffic_type in [\"normal\", \"attack\"]:\n",
    "        traffic_path = os.path.join(common_path, traffic_type)\n",
    "        for filename in os.listdir(traffic_path):\n",
    "            # Извлечение размера выборки из имени файла с помощью регулярного выражения\n",
    "            match = re.search(r\"_(\\d+)_\\d+_\", filename)\n",
    "            if match:\n",
    "                packet_intervals.add(int(match.group(1)))\n",
    "\n",
    "# Сортируем размеры выборок\n",
    "packet_intervals = sorted(packet_intervals)\n",
    "print(\"Найденные размеры выборок пакетов:\", packet_intervals)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../distributions/cauchy/csvs\n",
      "../../distributions/exponential/csvs\n",
      "../../distributions/normal/csvs\n",
      "../../distributions/gamma/csvs\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение данных для каждого размера выборки\n",
    "for packet_size in packet_intervals:\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for distro in distributions_folders:\n",
    "        attack_path = os.path.join(base_path, distro, \"csvs\")\n",
    "\n",
    "        # Определяем единственный файл нормального и атакующего трафика для текущего размера выборки\n",
    "        normal_file = next(\n",
    "                (\n",
    "                        f\n",
    "                        for f in os.listdir(os.path.join(attack_path, \"normal\"))\n",
    "                        if f\"_{packet_size}_0_\" in f\n",
    "                        ),\n",
    "                None,\n",
    "                )\n",
    "        attack_file = next(\n",
    "                (\n",
    "                        f\n",
    "                        for f in os.listdir(os.path.join(attack_path, \"attack\"))\n",
    "                        if f\"_{packet_size}_1_\" in f\n",
    "                        ),\n",
    "                None,\n",
    "                )\n",
    "\n",
    "        if normal_file and attack_file:\n",
    "            # Чтение файла с нормальным трафиком и добавление метки\n",
    "            normal_df = pd.read_csv(os.path.join(attack_path, \"normal\", normal_file))\n",
    "            normal_df[\"Label\"] = 0  # Метка для нормального трафика\n",
    "            combined_df = pd.concat([combined_df, normal_df], ignore_index=True)\n",
    "\n",
    "            # Чтение файла с атакующим трафиком и добавление метки\n",
    "            attack_df = pd.read_csv(os.path.join(attack_path, \"attack\", attack_file))\n",
    "            attack_df[\"Label\"] = distro_labels[distro]  # Уникальная метка для атаки\n",
    "            combined_df = pd.concat([combined_df, attack_df], ignore_index=True)\n",
    "\n",
    "    # Сохранение объединенного CSV для текущего размера выборки\n",
    "    combined_file = os.path.join(combined_path, f\"combined_{packet_size}_packets.csv\")\n",
    "    combined_df.to_csv(combined_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2-12",
   "language": "python",
   "name": "tf-2-12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
