{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T19:55:47.807197Z",
     "iopub.status.busy": "2024-11-13T19:55:47.806344Z",
     "iopub.status.idle": "2024-11-13T19:55:47.868894Z",
     "shell.execute_reply": "2024-11-13T19:55:47.868038Z",
     "shell.execute_reply.started": "2024-11-13T19:55:47.807171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    ")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T19:55:47.871279Z",
     "iopub.status.busy": "2024-11-13T19:55:47.870239Z",
     "iopub.status.idle": "2024-11-13T20:11:16.831563Z",
     "shell.execute_reply": "2024-11-13T20:11:16.830905Z",
     "shell.execute_reply.started": "2024-11-13T19:55:47.871252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   13.8s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2981            1.34m\n",
      "         2           1.2377            1.34m\n",
      "         3           1.1881            1.31m\n",
      "         4           1.1466            1.28m\n",
      "         5           1.1120            1.26m\n",
      "         6           1.0830            1.24m\n",
      "         7           1.0586            1.24m\n",
      "         8           1.0374            1.23m\n",
      "         9           1.0195            1.21m\n",
      "        10           1.0045            1.19m\n",
      "        20           0.9301            1.04m\n",
      "        30           0.9093           54.58s\n",
      "        40           0.9012           46.92s\n",
      "        50           0.8970           39.07s\n",
      "        60           0.8945           31.21s\n",
      "        70           0.8927           23.41s\n",
      "        80           0.8909           15.67s\n",
      "        90           0.8890            7.82s\n",
      "       100           0.8879            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 247 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:  11%|█         | 1/9 [06:18<50:29, 378.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2870           17.11s\n",
      "         2           1.2178           16.99s\n",
      "         3           1.1608           17.06s\n",
      "         4           1.1134           16.86s\n",
      "         5           1.0737           16.65s\n",
      "         6           1.0400           16.36s\n",
      "         7           1.0115           16.09s\n",
      "         8           0.9872           15.90s\n",
      "         9           0.9664           15.66s\n",
      "        10           0.9486           15.43s\n",
      "        20           0.8576           13.71s\n",
      "        30           0.8314           12.03s\n",
      "        40           0.8196           10.30s\n",
      "        50           0.8125            8.58s\n",
      "        60           0.8076            6.88s\n",
      "        70           0.8043            5.15s\n",
      "        80           0.8014            3.44s\n",
      "        90           0.7991            1.72s\n",
      "       100           0.7963            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 140 epochs took 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:  22%|██▏       | 2/9 [06:48<20:12, 173.26s/it][Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2803            9.20s\n",
      "         2           1.2055            9.20s\n",
      "         3           1.1440            9.18s\n",
      "         4           1.0926            9.02s\n",
      "         5           1.0493            8.87s\n",
      "         6           1.0123            8.71s\n",
      "         7           0.9808            8.52s\n",
      "         8           0.9538            8.42s\n",
      "         9           0.9304            8.31s\n",
      "        10           0.9103            8.17s\n",
      "        20           0.8062            7.24s\n",
      "        30           0.7735            6.35s\n",
      "        40           0.7607            5.44s\n",
      "        50           0.7536            4.54s\n",
      "        60           0.7485            3.63s\n",
      "        70           0.7450            2.71s\n",
      "        80           0.7418            1.81s\n",
      "        90           0.7390            0.91s\n",
      "       100           0.7373            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  33%|███▎      | 3/9 [07:14<10:36, 106.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 13 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2742            4.16s\n",
      "         2           1.1956            4.11s\n",
      "         3           1.1297            4.10s\n",
      "         4           1.0750            4.03s\n",
      "         5           1.0284            3.97s\n",
      "         6           0.9889            3.88s\n",
      "         7           0.9556            3.81s\n",
      "         8           0.9268            3.76s\n",
      "         9           0.9019            3.72s\n",
      "        10           0.8798            3.65s\n",
      "        20           0.7664            3.23s\n",
      "        30           0.7313            2.83s\n",
      "        40           0.7177            2.42s\n",
      "        50           0.7100            2.01s\n",
      "        60           0.7050            1.61s\n",
      "        70           0.7013            1.20s\n",
      "        80           0.6977            0.81s\n",
      "        90           0.6949            0.41s\n",
      "       100           0.6926            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  44%|████▍     | 4/9 [07:24<05:40, 68.06s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 787 epochs took 4 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2672            2.18s\n",
      "         2           1.1814            2.20s\n",
      "         3           1.1106            2.20s\n",
      "         4           1.0513            2.16s\n",
      "         5           1.0013            2.13s\n",
      "         6           0.9587            2.10s\n",
      "         7           0.9220            2.06s\n",
      "         8           0.8907            2.03s\n",
      "         9           0.8632            2.01s\n",
      "        10           0.8387            1.98s\n",
      "        20           0.7108            1.75s\n",
      "        30           0.6678            1.53s\n",
      "        40           0.6491            1.31s\n",
      "        50           0.6386            1.09s\n",
      "        60           0.6310            0.87s\n",
      "        70           0.6248            0.65s\n",
      "        80           0.6203            0.44s\n",
      "        90           0.6159            0.22s\n",
      "       100           0.6122            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  56%|█████▌    | 5/9 [07:29<03:02, 45.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 3 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2580            1.58s\n",
      "         2           1.1652            1.57s\n",
      "         3           1.0880            1.58s\n",
      "         4           1.0228            1.56s\n",
      "         5           0.9675            1.54s\n",
      "         6           0.9207            1.52s\n",
      "         7           0.8799            1.49s\n",
      "         8           0.8451            1.47s\n",
      "         9           0.8144            1.46s\n",
      "        10           0.7870            1.43s\n",
      "        20           0.6428            1.26s\n",
      "        30           0.5934            1.10s\n",
      "        40           0.5717            0.93s\n",
      "        50           0.5599            0.78s\n",
      "        60           0.5523            0.62s\n",
      "        70           0.5457            0.46s\n",
      "        80           0.5407            0.31s\n",
      "        90           0.5359            0.15s\n",
      "       100           0.5315            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  67%|██████▋   | 6/9 [07:33<01:34, 31.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 2 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2506            1.19s\n",
      "         2           1.1511            1.22s\n",
      "         3           1.0680            1.23s\n",
      "         4           0.9987            1.22s\n",
      "         5           0.9396            1.20s\n",
      "         6           0.8894            1.19s\n",
      "         7           0.8456            1.17s\n",
      "         8           0.8076            1.15s\n",
      "         9           0.7747            1.14s\n",
      "        10           0.7459            1.12s\n",
      "        20           0.5949            1.00s\n",
      "        30           0.5416            0.87s\n",
      "        40           0.5176            0.75s\n",
      "        50           0.5041            0.62s\n",
      "        60           0.4949            0.50s\n",
      "        70           0.4873            0.37s\n",
      "        80           0.4812            0.25s\n",
      "        90           0.4762            0.12s\n",
      "       100           0.4716            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  78%|███████▊  | 7/9 [07:37<00:44, 22.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2260            0.39s\n",
      "         2           1.1063            0.39s\n",
      "         3           1.0067            0.42s\n",
      "         4           0.9224            0.41s\n",
      "         5           0.8479            0.42s\n",
      "         6           0.7825            0.41s\n",
      "         7           0.7269            0.40s\n",
      "         8           0.6801            0.40s\n",
      "         9           0.6381            0.39s\n",
      "        10           0.6003            0.40s\n",
      "        20           0.3902            0.35s\n",
      "        30           0.3120            0.30s\n",
      "        40           0.2706            0.26s\n",
      "        50           0.2386            0.21s\n",
      "        60           0.2144            0.17s\n",
      "        70           0.2019            0.12s\n",
      "        80           0.1882            0.08s\n",
      "        90           0.1751            0.04s\n",
      "       100           0.1620            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  89%|████████▉ | 8/9 [07:38<00:15, 15.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 913 epochs took 0 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2126            0.49s\n",
      "         2           1.0819            0.39s\n",
      "         3           0.9731            0.36s\n",
      "         4           0.8810            0.31s\n",
      "         5           0.8024            0.30s\n",
      "         6           0.7349            0.28s\n",
      "         7           0.6761            0.28s\n",
      "         8           0.6236            0.26s\n",
      "         9           0.5780            0.26s\n",
      "        10           0.5381            0.26s\n",
      "        20           0.3101            0.22s\n",
      "        30           0.2194            0.19s\n",
      "        40           0.1744            0.16s\n",
      "        50           0.1356            0.13s\n",
      "        60           0.1095            0.10s\n",
      "        70           0.0924            0.08s\n",
      "        80           0.0797            0.05s\n",
      "        90           0.0667            0.03s\n",
      "       100           0.0576            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов: 100%|██████████| 9/9 [07:39<00:00, 51.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 722 epochs took 0 seconds\n",
      "Итоговый файл сохранён в 'final_multiclass_models_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Путь к объединенным CSV-файлам\n",
    "combined_path = \"combined_csvs\"\n",
    "combined_files = [f for f in os.listdir(combined_path) if f.endswith(\".csv\")]\n",
    "\n",
    "# Сортировка файлов по числу пакетов (например, _250_)\n",
    "combined_files.sort(key=lambda f: int(re.search(r\"(\\d+)_packets\", f).group(1)))\n",
    "\n",
    "# Словарь моделей с параметром verbose\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, verbose=1, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42, verbose=1),\n",
    "    \"SVM\": LinearSVC(verbose=1, random_state=42),\n",
    "    \"k-NN\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        multi_class=\"ovr\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=1000,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Создание папки для промежуточных файлов\n",
    "intermediate_path = \"binary_class_models_results\"\n",
    "os.makedirs(intermediate_path, exist_ok=True)\n",
    "\n",
    "# Итоговый список для всех результатов\n",
    "all_results = []\n",
    "\n",
    "# Проход по каждому CSV-файлу\n",
    "for combined_file in tqdm(combined_files, desc=\"Обработка файлов\"):\n",
    "    df = pd.read_csv(os.path.join(combined_path, combined_file))\n",
    "    X = df.drop(columns=[\"Label\"])\n",
    "    y = df[\"Label\"]\n",
    "\n",
    "    # Извлечение размера пакетов из имени файла\n",
    "    packet_size = int(re.search(r\"(\\d+)_packets\", combined_file).group(1))\n",
    "\n",
    "    # Разделение данных и нормализация в отдельном блоке try\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    except ValueError as e:\n",
    "        print(f\"  ! Ошибка при подготовке данных для файла '{combined_file}': {e}\")\n",
    "        continue\n",
    "\n",
    "    # Проход по каждой модели\n",
    "    for model_name, model in models.items():\n",
    "        results = {\n",
    "            \"Model\": model_name,\n",
    "            \"File\": combined_file,\n",
    "            \"Packet Size\": packet_size,\n",
    "        }\n",
    "\n",
    "        print(f\"  - Обучение модели {model_name}\")\n",
    "        try:\n",
    "            # Обучение модели с выводом прогресса\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Расчёт метрик\n",
    "            results[\"Accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "            results[\"Macro F1 Score\"] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "            results[\"Micro F1 Score\"] = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            results[\"Weighted F1 Score\"] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "            results[\"Macro Precision\"] = precision_score(\n",
    "                y_test, y_pred, average=\"macro\"\n",
    "            )\n",
    "            results[\"Micro Precision\"] = precision_score(\n",
    "                y_test, y_pred, average=\"micro\"\n",
    "            )\n",
    "            results[\"Cohen's Kappa\"] = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "            # Отчёт по каждому классу\n",
    "            class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            for label, metrics in class_report.items():\n",
    "                if isinstance(metrics, dict):\n",
    "                    results[f\"Precision_{label}\"] = metrics[\"precision\"]\n",
    "                    results[f\"Recall_{label}\"] = metrics[\"recall\"]\n",
    "                    results[f\"F1_{label}\"] = metrics[\"f1-score\"]\n",
    "\n",
    "        except ValueError as e:\n",
    "            # Пропуск метрик при ошибке\n",
    "            results.update(\n",
    "                {\n",
    "                    \"Accuracy\": \"0.0\",\n",
    "                    \"Macro F1 Score\": \"0.0\",\n",
    "                    \"Micro F1 Score\": \"0.0\",\n",
    "                    \"Weighted F1 Score\": \"0.0\",\n",
    "                    \"Macro Precision\": \"0.0\",\n",
    "                    \"Micro Precision\": \"0.0\",\n",
    "                    \"Cohen's Kappa\": \"0.0\",\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"  ! Ошибка обучения модели '{model_name}' для файла '{combined_file}': {e}\"\n",
    "            )\n",
    "\n",
    "        # Добавление результата\n",
    "        all_results.append(results)\n",
    "\n",
    "        # Промежуточный CSV для модели\n",
    "        model_results_df = pd.DataFrame([results])\n",
    "        model_results_file = os.path.join(\n",
    "            intermediate_path, f\"{model_name}_multiclass_results.csv\"\n",
    "        )\n",
    "\n",
    "        # Если файл существует, добавляем данные\n",
    "        if os.path.exists(model_results_file):\n",
    "            model_results_df.to_csv(\n",
    "                model_results_file, mode=\"a\", index=False, header=False, float_format=\"%.3f\"\n",
    "            )\n",
    "        else:\n",
    "            model_results_df.to_csv(model_results_file, index=False, float_format=\"%.3f\")\n",
    "\n",
    "# Итоговый файл с результатами всех моделей\n",
    "final_results_df = pd.DataFrame(all_results)\n",
    "final_results_df.to_csv(\"final_multiclass_models_results.csv\", index=False, float_format=\"%.3f\")\n",
    "print(\"Итоговый файл сохранён в 'final_multiclass_models_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T20:11:16.833090Z",
     "iopub.status.busy": "2024-11-13T20:11:16.832504Z",
     "iopub.status.idle": "2024-11-13T20:11:17.051061Z",
     "shell.execute_reply": "2024-11-13T20:11:17.050478Z",
     "shell.execute_reply.started": "2024-11-13T20:11:16.833066Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создание папки для модифицированных промежуточных файлов\n",
    "intermediate_path_modified = \"binary_class_models_results_modified\"\n",
    "os.makedirs(intermediate_path_modified, exist_ok=True)\n",
    "\n",
    "# Путь к промежуточным файлам\n",
    "intermediate_path = \"binary_class_models_results\"\n",
    "model_results_files = [f for f in os.listdir(intermediate_path) if f.endswith(\"_multiclass_results.csv\")]\n",
    "\n",
    "# Создаем итоговый DataFrame для всех моделей\n",
    "final_results = []\n",
    "\n",
    "# Процесс обработки каждого промежуточного файла модели\n",
    "for model_results_file in model_results_files:\n",
    "    # Чтение промежуточного CSV файла\n",
    "    df = pd.read_csv(os.path.join(intermediate_path, model_results_file))\n",
    "    # display(df)\n",
    "\n",
    "    # Получаем список метрик, исключая \"Packet Size\" и \"Model\"\n",
    "    metrics_columns = [col for col in df.columns if col not in ['Packet Size', 'Model', 'File']]\n",
    "\n",
    "    # Определение лучшей выборки для каждой метрики\n",
    "    best = {}\n",
    "    counts = {}\n",
    "\n",
    "    # Добавление столбца Counts для каждой выборки\n",
    "    max1_counts_column = []\n",
    "    for index, row in df.iterrows():\n",
    "        max1_count = sum(1 for col in metrics_columns if row[col] == df[col].max())  # Считаем, сколько раз максимальное значение встречается\n",
    "        max1_counts_column.append(max1_count)\n",
    "\n",
    "    df[\"max 1\"] = max1_counts_column\n",
    "\n",
    "    # Для каждой метрики находим наилучшие выборки\n",
    "    for col in metrics_columns:  # Перебираем только метрики\n",
    "        max_value = df[col].max()  # Находим максимальное значение для метрики\n",
    "        best[col] = df[df[col] == max_value][\"Packet Size\"].tolist()  # Сохраняем размеры выборок с максимальным значением\n",
    "\n",
    "        # Подсчитаем, сколько раз каждая выборка была максимальной для этой метрики\n",
    "        counts[col] = df[col].value_counts().get(max_value, 0)  # Подсчитаем сколько раз максимальное значение встречается\n",
    "\n",
    "    # Строка Best\n",
    "    best_row = {\"Packet Size\": \"Best\"}\n",
    "    for col in metrics_columns:\n",
    "        best_row[col] = best[col]  # Присваиваем лучшие выборки для каждой метрики\n",
    "\n",
    "    # Добавление строки Best в DataFrame\n",
    "    df_best = pd.DataFrame([best_row])\n",
    "\n",
    "    # Добавление строки Best в DataFrame\n",
    "    df = pd.concat([df, df_best], ignore_index=True)\n",
    "    \n",
    "    model_results_file_modified = os.path.join(\n",
    "            intermediate_path_modified, f\"{os.path.splitext(model_results_file)[0]}_modified.csv\"\n",
    "        )\n",
    "\n",
    "    # Запись результатов в новый CSV файл\n",
    "    df.to_csv(model_results_file_modified, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
