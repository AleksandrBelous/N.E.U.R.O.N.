{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T19:55:47.807197Z",
     "iopub.status.busy": "2024-11-13T19:55:47.806344Z",
     "iopub.status.idle": "2024-11-13T19:55:47.868894Z",
     "shell.execute_reply": "2024-11-13T19:55:47.868038Z",
     "shell.execute_reply.started": "2024-11-13T19:55:47.807171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    ")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T19:55:47.871279Z",
     "iopub.status.busy": "2024-11-13T19:55:47.870239Z",
     "iopub.status.idle": "2024-11-13T20:11:16.831563Z",
     "shell.execute_reply": "2024-11-13T20:11:16.830905Z",
     "shell.execute_reply.started": "2024-11-13T19:55:47.871252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.5s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2031            1.39m\n",
      "         2           1.0769            1.30m\n",
      "         3           0.9718            1.29m\n",
      "         4           0.8838            1.25m\n",
      "         5           0.8094            1.23m\n",
      "         6           0.7448            1.20m\n",
      "         7           0.6895            1.18m\n",
      "         8           0.6417            1.16m\n",
      "         9           0.6002            1.14m\n",
      "        10           0.5640            1.12m\n",
      "        20           0.3713           58.57s\n",
      "        30           0.3090           51.55s\n",
      "        40           0.2819           44.27s\n",
      "        50           0.2661           36.75s\n",
      "        60           0.2527           29.34s\n",
      "        70           0.2437           22.08s\n",
      "        80           0.2375           14.77s\n",
      "        90           0.2314            7.43s\n",
      "       100           0.2280            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 187 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:  11%|█         | 1/9 [05:04<40:38, 304.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1898           16.62s\n",
      "         2           1.0518           16.41s\n",
      "         3           0.9377           16.29s\n",
      "         4           0.8415           16.09s\n",
      "         5           0.7598           15.89s\n",
      "         6           0.6891           15.58s\n",
      "         7           0.6287           15.28s\n",
      "         8           0.5753           15.07s\n",
      "         9           0.5293           14.91s\n",
      "        10           0.4881           14.63s\n",
      "        20           0.2655           13.12s\n",
      "        30           0.1895           11.56s\n",
      "        40           0.1605            9.93s\n",
      "        50           0.1477            8.27s\n",
      "        60           0.1401            6.61s\n",
      "        70           0.1355            4.94s\n",
      "        80           0.1314            3.30s\n",
      "        90           0.1280            1.65s\n",
      "       100           0.1244            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 22 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:  22%|██▏       | 2/9 [05:50<17:44, 152.14s/it][Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.5s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1828            9.60s\n",
      "         2           1.0394            9.21s\n",
      "         3           0.9205            9.02s\n",
      "         4           0.8206            8.78s\n",
      "         5           0.7356            8.68s\n",
      "         6           0.6623            8.46s\n",
      "         7           0.5985            8.30s\n",
      "         8           0.5433            8.18s\n",
      "         9           0.4946            8.07s\n",
      "        10           0.4519            7.91s\n",
      "        20           0.2196            7.02s\n",
      "        30           0.1421            6.15s\n",
      "        40           0.1139            5.27s\n",
      "        50           0.1024            4.38s\n",
      "        60           0.0972            3.51s\n",
      "        70           0.0929            2.62s\n",
      "        80           0.0896            1.75s\n",
      "        90           0.0867            0.88s\n",
      "       100           0.0849            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  33%|███▎      | 3/9 [06:12<09:17, 92.88s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1817            4.06s\n",
      "         2           1.0372            3.97s\n",
      "         3           0.9177            3.91s\n",
      "         4           0.8169            4.08s\n",
      "         5           0.7316            4.08s\n",
      "         6           0.6579            3.95s\n",
      "         7           0.5946            3.86s\n",
      "         8           0.5389            3.79s\n",
      "         9           0.4906            3.72s\n",
      "        10           0.4480            3.63s\n",
      "        20           0.2176            3.17s\n",
      "        30           0.1414            2.81s\n",
      "        40           0.1139            2.39s\n",
      "        50           0.1018            1.99s\n",
      "        60           0.0978            1.58s\n",
      "        70           0.0948            1.18s\n",
      "        80           0.0913            0.78s\n",
      "        90           0.0891            0.40s\n",
      "       100           0.0854            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  44%|████▍     | 4/9 [06:22<05:00, 60.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1844            2.18s\n",
      "         2           1.0424            2.20s\n",
      "         3           0.9229            2.17s\n",
      "         4           0.8225            2.11s\n",
      "         5           0.7370            2.11s\n",
      "         6           0.6641            2.07s\n",
      "         7           0.6005            2.03s\n",
      "         8           0.5462            2.01s\n",
      "         9           0.4979            1.98s\n",
      "        10           0.4559            1.95s\n",
      "        20           0.2272            1.73s\n",
      "        30           0.1523            1.52s\n",
      "        40           0.1239            1.31s\n",
      "        50           0.1119            1.09s\n",
      "        60           0.1053            0.87s\n",
      "        70           0.1008            0.65s\n",
      "        80           0.0971            0.43s\n",
      "        90           0.0938            0.22s\n",
      "       100           0.0916            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  56%|█████▌    | 5/9 [06:26<02:39, 39.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 481 epochs took 1 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1846            1.88s\n",
      "         2           1.0426            1.86s\n",
      "         3           0.9247            1.87s\n",
      "         4           0.8256            1.87s\n",
      "         5           0.7414            1.82s\n",
      "         6           0.6691            1.80s\n",
      "         7           0.6063            1.77s\n",
      "         8           0.5518            1.75s\n",
      "         9           0.5041            1.73s\n",
      "        10           0.4626            1.70s\n",
      "        20           0.2344            1.42s\n",
      "        30           0.1553            1.20s\n",
      "        40           0.1270            1.01s\n",
      "        50           0.1138            0.83s\n",
      "        60           0.1065            0.67s\n",
      "        70           0.1020            0.50s\n",
      "        80           0.0965            0.33s\n",
      "        90           0.0923            0.17s\n",
      "       100           0.0859            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  67%|██████▋   | 6/9 [06:30<01:22, 27.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 792 epochs took 1 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1841            1.29s\n",
      "         2           1.0418            1.28s\n",
      "         3           0.9240            1.26s\n",
      "         4           0.8243            1.25s\n",
      "         5           0.7391            1.22s\n",
      "         6           0.6658            1.21s\n",
      "         7           0.6027            1.20s\n",
      "         8           0.5479            1.18s\n",
      "         9           0.4999            1.17s\n",
      "        10           0.4579            1.15s\n",
      "        20           0.2275            1.03s\n",
      "        30           0.1506            0.89s\n",
      "        40           0.1207            0.77s\n",
      "        50           0.1008            0.66s\n",
      "        60           0.0887            0.52s\n",
      "        70           0.0810            0.40s\n",
      "        80           0.0734            0.26s\n",
      "        90           0.0675            0.13s\n",
      "       100           0.0634            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  78%|███████▊  | 7/9 [06:33<00:39, 19.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 1 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1755            0.30s\n",
      "         2           1.0262            0.34s\n",
      "         3           0.9023            0.32s\n",
      "         4           0.7978            0.31s\n",
      "         5           0.7089            0.30s\n",
      "         6           0.6315            0.31s\n",
      "         7           0.5646            0.31s\n",
      "         8           0.5064            0.31s\n",
      "         9           0.4544            0.31s\n",
      "        10           0.4092            0.31s\n",
      "        20           0.1562            0.26s\n",
      "        30           0.0647            0.24s\n",
      "        40           0.0292            0.21s\n",
      "        50           0.0144            0.18s\n",
      "        60           0.0076            0.14s\n",
      "        70           0.0045            0.11s\n",
      "        80           0.0024            0.07s\n",
      "        90           0.0015            0.04s\n",
      "       100           0.0009            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n",
      "convergence after 447 epochs took 1 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  89%|████████▉ | 8/9 [06:34<00:13, 13.69s/it][Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1712            0.30s\n",
      "         2           1.0184            0.24s\n",
      "         3           0.8918            0.26s\n",
      "         4           0.7852            0.24s\n",
      "         5           0.6944            0.23s\n",
      "         6           0.6163            0.22s\n",
      "         7           0.5487            0.23s\n",
      "         8           0.4898            0.22s\n",
      "         9           0.4383            0.21s\n",
      "        10           0.3930            0.22s\n",
      "        20           0.1428            0.18s\n",
      "        30           0.0546            0.16s\n",
      "        40           0.0219            0.14s\n",
      "        50           0.0088            0.12s\n",
      "        60           0.0032            0.10s\n",
      "        70           0.0012            0.07s\n",
      "        80           0.0004            0.05s\n",
      "        90           0.0002            0.03s\n",
      "       100           0.0001            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов: 100%|██████████| 9/9 [06:35<00:00, 43.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 298 epochs took 0 seconds\n",
      "Итоговый файл сохранён в 'final_multiclass_models_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Путь к объединенным CSV-файлам\n",
    "combined_path = \"combined_csvs\"\n",
    "combined_files = [f for f in os.listdir(combined_path) if f.endswith(\".csv\")]\n",
    "\n",
    "# Сортировка файлов по числу пакетов (например, _250_)\n",
    "combined_files.sort(key=lambda f: int(re.search(r\"(\\d+)_packets\", f).group(1)))\n",
    "\n",
    "# Словарь моделей с параметром verbose\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, verbose=1, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42, verbose=1),\n",
    "    \"SVM\": LinearSVC(verbose=1, random_state=42),\n",
    "    \"k-NN\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        multi_class=\"ovr\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=1000,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Создание папки для промежуточных файлов\n",
    "intermediate_path = \"binary_class_models_results\"\n",
    "os.makedirs(intermediate_path, exist_ok=True)\n",
    "\n",
    "# Итоговый список для всех результатов\n",
    "all_results = []\n",
    "\n",
    "# Проход по каждому CSV-файлу\n",
    "for combined_file in tqdm(combined_files, desc=\"Обработка файлов\"):\n",
    "    df = pd.read_csv(os.path.join(combined_path, combined_file))\n",
    "    X = df.drop(columns=[\"Label\"])\n",
    "    y = df[\"Label\"]\n",
    "\n",
    "    # Извлечение размера пакетов из имени файла\n",
    "    packet_size = int(re.search(r\"(\\d+)_packets\", combined_file).group(1))\n",
    "\n",
    "    # Разделение данных и нормализация в отдельном блоке try\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    except ValueError as e:\n",
    "        print(f\"  ! Ошибка при подготовке данных для файла '{combined_file}': {e}\")\n",
    "        continue\n",
    "\n",
    "    # Проход по каждой модели\n",
    "    for model_name, model in models.items():\n",
    "        results = {\n",
    "            \"Model\": model_name,\n",
    "            \"File\": combined_file,\n",
    "            \"Packet Size\": packet_size,\n",
    "        }\n",
    "\n",
    "        print(f\"  - Обучение модели {model_name}\")\n",
    "        try:\n",
    "            # Обучение модели с выводом прогресса\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Расчёт метрик\n",
    "            results[\"Accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "            results[\"Macro F1 Score\"] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "            results[\"Micro F1 Score\"] = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            results[\"Weighted F1 Score\"] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "            results[\"Macro Precision\"] = precision_score(\n",
    "                y_test, y_pred, average=\"macro\"\n",
    "            )\n",
    "            results[\"Micro Precision\"] = precision_score(\n",
    "                y_test, y_pred, average=\"micro\"\n",
    "            )\n",
    "            results[\"Cohen's Kappa\"] = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "            # Отчёт по каждому классу\n",
    "            class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            for label, metrics in class_report.items():\n",
    "                if isinstance(metrics, dict):\n",
    "                    results[f\"Precision_{label}\"] = metrics[\"precision\"]\n",
    "                    results[f\"Recall_{label}\"] = metrics[\"recall\"]\n",
    "                    results[f\"F1_{label}\"] = metrics[\"f1-score\"]\n",
    "\n",
    "        except ValueError as e:\n",
    "            # Пропуск метрик при ошибке\n",
    "            results.update(\n",
    "                {\n",
    "                    \"Accuracy\": \"0.0\",\n",
    "                    \"Macro F1 Score\": \"0.0\",\n",
    "                    \"Micro F1 Score\": \"0.0\",\n",
    "                    \"Weighted F1 Score\": \"0.0\",\n",
    "                    \"Macro Precision\": \"0.0\",\n",
    "                    \"Micro Precision\": \"0.0\",\n",
    "                    \"Cohen's Kappa\": \"0.0\",\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"  ! Ошибка обучения модели '{model_name}' для файла '{combined_file}': {e}\"\n",
    "            )\n",
    "\n",
    "        # Добавление результата\n",
    "        all_results.append(results)\n",
    "\n",
    "        # Промежуточный CSV для модели\n",
    "        model_results_df = pd.DataFrame([results])\n",
    "        model_results_file = os.path.join(\n",
    "            intermediate_path, f\"{model_name}_multiclass_results.csv\"\n",
    "        )\n",
    "\n",
    "        # Если файл существует, добавляем данные\n",
    "        if os.path.exists(model_results_file):\n",
    "            model_results_df.to_csv(\n",
    "                model_results_file, mode=\"a\", index=False, header=False, float_format=\"%.3f\"\n",
    "            )\n",
    "        else:\n",
    "            model_results_df.to_csv(model_results_file, index=False, float_format=\"%.3f\")\n",
    "\n",
    "# Итоговый файл с результатами всех моделей\n",
    "final_results_df = pd.DataFrame(all_results)\n",
    "final_results_df.to_csv(\"final_multiclass_models_results.csv\", index=False, float_format=\"%.3f\")\n",
    "print(\"Итоговый файл сохранён в 'final_multiclass_models_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T20:11:16.833090Z",
     "iopub.status.busy": "2024-11-13T20:11:16.832504Z",
     "iopub.status.idle": "2024-11-13T20:11:17.051061Z",
     "shell.execute_reply": "2024-11-13T20:11:17.050478Z",
     "shell.execute_reply.started": "2024-11-13T20:11:16.833066Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создание папки для модифицированных промежуточных файлов\n",
    "intermediate_path_modified = \"binary_class_models_results_modified/\"\n",
    "os.makedirs(intermediate_path_modified, exist_ok=True)\n",
    "\n",
    "# Путь к промежуточным файлам\n",
    "intermediate_path = \"binary_class_models_results/\"\n",
    "model_results_files = [f for f in os.listdir(intermediate_path) if f.endswith(\"_multiclass_results.csv\")]\n",
    "\n",
    "# Создаем итоговый DataFrame для всех моделей\n",
    "final_results = []\n",
    "\n",
    "# Процесс обработки каждого промежуточного файла модели\n",
    "for model_results_file in model_results_files:\n",
    "    # Чтение промежуточного CSV файла\n",
    "    df = pd.read_csv(os.path.join(intermediate_path, model_results_file))\n",
    "    # display(df)\n",
    "\n",
    "    # Получаем список метрик, исключая \"Packet Size\" и \"Model\"\n",
    "    metrics_columns = [col for col in df.columns if col not in ['Packet Size', 'Model', 'File']]\n",
    "\n",
    "    # Определение лучшей выборки для каждой метрики\n",
    "    best = {}\n",
    "    counts = {}\n",
    "\n",
    "    # Добавление столбца Counts для каждой выборки\n",
    "    max1_counts_column = []\n",
    "    for index, row in df.iterrows():\n",
    "        max1_count = sum(1 for col in metrics_columns if row[col] == df[col].max())  # Считаем, сколько раз максимальное значение встречается\n",
    "        max1_counts_column.append(max1_count)\n",
    "\n",
    "    df[\"max 1\"] = max1_counts_column\n",
    "\n",
    "    # Для каждой метрики находим наилучшие выборки\n",
    "    for col in metrics_columns:  # Перебираем только метрики\n",
    "        max_value = df[col].max()  # Находим максимальное значение для метрики\n",
    "        best[col] = df[df[col] == max_value][\"Packet Size\"].tolist()  # Сохраняем размеры выборок с максимальным значением\n",
    "\n",
    "        # Подсчитаем, сколько раз каждая выборка была максимальной для этой метрики\n",
    "        counts[col] = df[col].value_counts().get(max_value, 0)  # Подсчитаем сколько раз максимальное значение встречается\n",
    "\n",
    "    # Строка Best\n",
    "    best_row = {\"Packet Size\": \"Best\"}\n",
    "    for col in metrics_columns:\n",
    "        best_row[col] = best[col]  # Присваиваем лучшие выборки для каждой метрики\n",
    "\n",
    "    # Добавление строки Best в DataFrame\n",
    "    df_best = pd.DataFrame([best_row])\n",
    "\n",
    "    # Добавление строки Best в DataFrame\n",
    "    df = pd.concat([df, df_best], ignore_index=True)\n",
    "    \n",
    "    model_results_file_modified = os.path.join(\n",
    "            intermediate_path_modified, f\"{os.path.splitext(model_results_file)[0]}_modified.csv\"\n",
    "        )\n",
    "\n",
    "    # Запись результатов в новый CSV файл\n",
    "    df.to_csv(model_results_file_modified, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
