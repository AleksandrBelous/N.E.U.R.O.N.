{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T19:55:47.807197Z",
     "iopub.status.busy": "2024-11-13T19:55:47.806344Z",
     "iopub.status.idle": "2024-11-13T19:55:47.868894Z",
     "shell.execute_reply": "2024-11-13T19:55:47.868038Z",
     "shell.execute_reply.started": "2024-11-13T19:55:47.807171Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    cohen_kappa_score,\n",
    "    classification_report,\n",
    ")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T19:55:47.871279Z",
     "iopub.status.busy": "2024-11-13T19:55:47.870239Z",
     "iopub.status.idle": "2024-11-13T20:11:16.831563Z",
     "shell.execute_reply": "2024-11-13T20:11:16.830905Z",
     "shell.execute_reply.started": "2024-11-13T19:55:47.871252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:   0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   14.8s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2126            1.38m\n",
      "         2           1.0939            1.35m\n",
      "         3           0.9959            1.33m\n",
      "         4           0.9138            1.30m\n",
      "         5           0.8444            1.28m\n",
      "         6           0.7844            1.26m\n",
      "         7           0.7331            1.23m\n",
      "         8           0.6883            1.22m\n",
      "         9           0.6494            1.20m\n",
      "        10           0.6161            1.18m\n",
      "        20           0.4371            1.05m\n",
      "        30           0.3792           54.91s\n",
      "        40           0.3514           46.90s\n",
      "        50           0.3357           39.39s\n",
      "        60           0.3242           31.44s\n",
      "        70           0.3156           23.41s\n",
      "        80           0.3095           15.58s\n",
      "        90           0.3055            7.79s\n",
      "       100           0.3018            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 206 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:  11%|█         | 1/9 [05:30<44:01, 330.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2001           18.70s\n",
      "         2           1.0714           18.32s\n",
      "         3           0.9650           17.97s\n",
      "         4           0.8752           17.60s\n",
      "         5           0.7991           17.35s\n",
      "         6           0.7335           16.99s\n",
      "         7           0.6770           16.73s\n",
      "         8           0.6263           16.49s\n",
      "         9           0.5837           16.24s\n",
      "        10           0.5462           15.98s\n",
      "        20           0.3407           14.19s\n",
      "        30           0.2711           12.46s\n",
      "        40           0.2405           10.67s\n",
      "        50           0.2263            8.89s\n",
      "        60           0.2173            7.11s\n",
      "        70           0.2107            5.32s\n",
      "        80           0.2060            3.55s\n",
      "        90           0.2022            1.78s\n",
      "       100           0.1993            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 25 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Обработка файлов:  22%|██▏       | 2/9 [06:20<19:19, 165.62s/it][Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.7s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1906            9.80s\n",
      "         2           1.0551            9.75s\n",
      "         3           0.9420            9.70s\n",
      "         4           0.8474            9.55s\n",
      "         5           0.7665            9.44s\n",
      "         6           0.6974            9.27s\n",
      "         7           0.6377            9.08s\n",
      "         8           0.5855            8.98s\n",
      "         9           0.5394            8.85s\n",
      "        10           0.5000            8.69s\n",
      "        20           0.2759            7.75s\n",
      "        30           0.1989            6.80s\n",
      "        40           0.1705            5.85s\n",
      "        50           0.1569            4.87s\n",
      "        60           0.1496            3.88s\n",
      "        70           0.1451            2.91s\n",
      "        80           0.1421            1.94s\n",
      "        90           0.1394            0.98s\n",
      "       100           0.1368            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  33%|███▎      | 3/9 [06:45<10:08, 101.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 11 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1856            4.45s\n",
      "         2           1.0447            4.41s\n",
      "         3           0.9286            4.39s\n",
      "         4           0.8306            4.33s\n",
      "         5           0.7475            4.22s\n",
      "         6           0.6762            4.14s\n",
      "         7           0.6137            4.07s\n",
      "         8           0.5604            4.00s\n",
      "         9           0.5136            3.95s\n",
      "        10           0.4713            3.89s\n",
      "        20           0.2439            3.45s\n",
      "        30           0.1661            3.02s\n",
      "        40           0.1369            2.59s\n",
      "        50           0.1248            2.16s\n",
      "        60           0.1180            1.72s\n",
      "        70           0.1143            1.29s\n",
      "        80           0.1115            0.86s\n",
      "        90           0.1088            0.43s\n",
      "       100           0.1060            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  44%|████▍     | 4/9 [06:56<05:28, 65.61s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter reached after 5 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1838            2.28s\n",
      "         2           1.0417            2.35s\n",
      "         3           0.9238            2.30s\n",
      "         4           0.8247            2.28s\n",
      "         5           0.7399            2.24s\n",
      "         6           0.6676            2.22s\n",
      "         7           0.6045            2.18s\n",
      "         8           0.5503            2.16s\n",
      "         9           0.5027            2.13s\n",
      "        10           0.4604            2.10s\n",
      "        20           0.2303            1.85s\n",
      "        30           0.1528            1.64s\n",
      "        40           0.1216            1.41s\n",
      "        50           0.1085            1.17s\n",
      "        60           0.1007            0.94s\n",
      "        70           0.0956            0.70s\n",
      "        80           0.0915            0.47s\n",
      "        90           0.0887            0.23s\n",
      "       100           0.0845            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  56%|█████▌    | 5/9 [07:01<02:55, 43.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 776 epochs took 1 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1822            2.67s\n",
      "         2           1.0395            2.40s\n",
      "         3           0.9209            2.26s\n",
      "         4           0.8214            2.16s\n",
      "         5           0.7367            2.11s\n",
      "         6           0.6632            2.05s\n",
      "         7           0.6004            2.01s\n",
      "         8           0.5452            1.98s\n",
      "         9           0.4968            1.96s\n",
      "        10           0.4549            1.92s\n",
      "        20           0.2219            1.54s\n",
      "        30           0.1441            1.32s\n",
      "        40           0.1125            1.10s\n",
      "        50           0.0968            0.90s\n",
      "        60           0.0886            0.72s\n",
      "        70           0.0815            0.53s\n",
      "        80           0.0746            0.35s\n",
      "        90           0.0717            0.17s\n",
      "       100           0.0622            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  67%|██████▋   | 6/9 [07:05<01:30, 30.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 965 epochs took 1 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1829            1.68s\n",
      "         2           1.0410            1.67s\n",
      "         3           0.9234            1.65s\n",
      "         4           0.8243            1.61s\n",
      "         5           0.7403            1.58s\n",
      "         6           0.6675            1.55s\n",
      "         7           0.6047            1.53s\n",
      "         8           0.5497            1.51s\n",
      "         9           0.5020            1.49s\n",
      "        10           0.4591            1.47s\n",
      "        20           0.2298            1.21s\n",
      "        30           0.1498            1.02s\n",
      "        40           0.1181            0.86s\n",
      "        50           0.0997            0.71s\n",
      "        60           0.0905            0.56s\n",
      "        70           0.0863            0.42s\n",
      "        80           0.0821            0.28s\n",
      "        90           0.0788            0.14s\n",
      "       100           0.0755            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  78%|███████▊  | 7/9 [07:08<00:42, 21.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 790 epochs took 1 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1818            0.49s\n",
      "         2           1.0368            0.44s\n",
      "         3           0.9187            0.45s\n",
      "         4           0.8174            0.46s\n",
      "         5           0.7341            0.46s\n",
      "         6           0.6616            0.45s\n",
      "         7           0.5967            0.45s\n",
      "         8           0.5406            0.44s\n",
      "         9           0.4922            0.43s\n",
      "        10           0.4489            0.41s\n",
      "        20           0.2091            0.35s\n",
      "        30           0.1154            0.30s\n",
      "        40           0.0748            0.25s\n",
      "        50           0.0547            0.21s\n",
      "        60           0.0431            0.17s\n",
      "        70           0.0321            0.13s\n",
      "        80           0.0262            0.08s\n",
      "        90           0.0217            0.04s\n",
      "       100           0.0187            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов:  89%|████████▉ | 8/9 [07:10<00:15, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 555 epochs took 0 seconds\n",
      "  - Обучение модели Random Forest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=28)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "[Parallel(n_jobs=28)]: Done 100 out of 100 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Обучение модели Gradient Boosting\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1759            0.70s\n",
      "         2           1.0289            0.49s\n",
      "         3           0.9084            0.39s\n",
      "         4           0.8071            0.36s\n",
      "         5           0.7211            0.32s\n",
      "         6           0.6448            0.31s\n",
      "         7           0.5807            0.29s\n",
      "         8           0.5228            0.29s\n",
      "         9           0.4737            0.28s\n",
      "        10           0.4308            0.27s\n",
      "        20           0.1801            0.22s\n",
      "        30           0.0792            0.19s\n",
      "        40           0.0379            0.16s\n",
      "        50           0.0210            0.14s\n",
      "        60           0.0114            0.11s\n",
      "        70           0.0069            0.08s\n",
      "        80           0.0043            0.05s\n",
      "        90           0.0027            0.03s\n",
      "       100           0.0019            0.00s\n",
      "  - Обучение модели SVM\n",
      "[LibLinear]  - Обучение модели k-NN\n",
      "  - Обучение модели Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 28 concurrent workers.\n",
      "Обработка файлов: 100%|██████████| 9/9 [07:10<00:00, 47.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 425 epochs took 0 seconds\n",
      "Итоговый файл сохранён в 'final_multiclass_models_results.csv'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Путь к объединенным CSV-файлам\n",
    "combined_path = \"combined_csvs\"\n",
    "combined_files = [f for f in os.listdir(combined_path) if f.endswith(\".csv\")]\n",
    "\n",
    "# Сортировка файлов по числу пакетов (например, _250_)\n",
    "combined_files.sort(key=lambda f: int(re.search(r\"(\\d+)_packets\", f).group(1)))\n",
    "\n",
    "# Словарь моделей с параметром verbose\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42, verbose=1, n_jobs=-1),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42, verbose=1),\n",
    "    \"SVM\": LinearSVC(verbose=1, random_state=42),\n",
    "    \"k-NN\": KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "    \"Logistic Regression\": LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        multi_class=\"ovr\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=1000,\n",
    "        verbose=1,\n",
    "        n_jobs=-1,\n",
    "        random_state=42,\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Создание папки для промежуточных файлов\n",
    "intermediate_path = \"binary_class_models_results\"\n",
    "os.makedirs(intermediate_path, exist_ok=True)\n",
    "\n",
    "# Итоговый список для всех результатов\n",
    "all_results = []\n",
    "\n",
    "# Проход по каждому CSV-файлу\n",
    "for combined_file in tqdm(combined_files, desc=\"Обработка файлов\"):\n",
    "    df = pd.read_csv(os.path.join(combined_path, combined_file))\n",
    "    X = df.drop(columns=[\"Label\"])\n",
    "    y = df[\"Label\"]\n",
    "\n",
    "    # Извлечение размера пакетов из имени файла\n",
    "    packet_size = int(re.search(r\"(\\d+)_packets\", combined_file).group(1))\n",
    "\n",
    "    # Разделение данных и нормализация в отдельном блоке try\n",
    "    try:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=42, stratify=y\n",
    "        )\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    except ValueError as e:\n",
    "        print(f\"  ! Ошибка при подготовке данных для файла '{combined_file}': {e}\")\n",
    "        continue\n",
    "\n",
    "    # Проход по каждой модели\n",
    "    for model_name, model in models.items():\n",
    "        results = {\n",
    "            \"Model\": model_name,\n",
    "            \"File\": combined_file,\n",
    "            \"Packet Size\": packet_size,\n",
    "        }\n",
    "\n",
    "        print(f\"  - Обучение модели {model_name}\")\n",
    "        try:\n",
    "            # Обучение модели с выводом прогресса\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Расчёт метрик\n",
    "            results[\"Accuracy\"] = accuracy_score(y_test, y_pred)\n",
    "            results[\"Macro F1 Score\"] = f1_score(y_test, y_pred, average=\"macro\")\n",
    "            results[\"Micro F1 Score\"] = f1_score(y_test, y_pred, average=\"micro\")\n",
    "            results[\"Weighted F1 Score\"] = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "            results[\"Macro Precision\"] = precision_score(\n",
    "                y_test, y_pred, average=\"macro\"\n",
    "            )\n",
    "            results[\"Micro Precision\"] = precision_score(\n",
    "                y_test, y_pred, average=\"micro\"\n",
    "            )\n",
    "            results[\"Cohen's Kappa\"] = cohen_kappa_score(y_test, y_pred)\n",
    "\n",
    "            # Отчёт по каждому классу\n",
    "            class_report = classification_report(y_test, y_pred, output_dict=True)\n",
    "            for label, metrics in class_report.items():\n",
    "                if isinstance(metrics, dict):\n",
    "                    results[f\"Precision_{label}\"] = metrics[\"precision\"]\n",
    "                    results[f\"Recall_{label}\"] = metrics[\"recall\"]\n",
    "                    results[f\"F1_{label}\"] = metrics[\"f1-score\"]\n",
    "\n",
    "        except ValueError as e:\n",
    "            # Пропуск метрик при ошибке\n",
    "            results.update(\n",
    "                {\n",
    "                    \"Accuracy\": \"0.0\",\n",
    "                    \"Macro F1 Score\": \"0.0\",\n",
    "                    \"Micro F1 Score\": \"0.0\",\n",
    "                    \"Weighted F1 Score\": \"0.0\",\n",
    "                    \"Macro Precision\": \"0.0\",\n",
    "                    \"Micro Precision\": \"0.0\",\n",
    "                    \"Cohen's Kappa\": \"0.0\",\n",
    "                }\n",
    "            )\n",
    "            print(\n",
    "                f\"  ! Ошибка обучения модели '{model_name}' для файла '{combined_file}': {e}\"\n",
    "            )\n",
    "\n",
    "        # Добавление результата\n",
    "        all_results.append(results)\n",
    "\n",
    "        # Промежуточный CSV для модели\n",
    "        model_results_df = pd.DataFrame([results])\n",
    "        model_results_file = os.path.join(\n",
    "            intermediate_path, f\"{model_name}_multiclass_results.csv\"\n",
    "        )\n",
    "\n",
    "        # Если файл существует, добавляем данные\n",
    "        if os.path.exists(model_results_file):\n",
    "            model_results_df.to_csv(\n",
    "                model_results_file, mode=\"a\", index=False, header=False, float_format=\"%.3f\"\n",
    "            )\n",
    "        else:\n",
    "            model_results_df.to_csv(model_results_file, index=False, float_format=\"%.3f\")\n",
    "\n",
    "# Итоговый файл с результатами всех моделей\n",
    "final_results_df = pd.DataFrame(all_results)\n",
    "final_results_df.to_csv(\"final_multiclass_models_results.csv\", index=False, float_format=\"%.3f\")\n",
    "print(\"Итоговый файл сохранён в 'final_multiclass_models_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-13T20:11:16.833090Z",
     "iopub.status.busy": "2024-11-13T20:11:16.832504Z",
     "iopub.status.idle": "2024-11-13T20:11:17.051061Z",
     "shell.execute_reply": "2024-11-13T20:11:17.050478Z",
     "shell.execute_reply.started": "2024-11-13T20:11:16.833066Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Создание папки для модифицированных промежуточных файлов\n",
    "intermediate_path_modified = \"binary_class_models_results_modified\"\n",
    "os.makedirs(intermediate_path_modified, exist_ok=True)\n",
    "\n",
    "# Путь к промежуточным файлам\n",
    "intermediate_path = \"binary_class_models_results\"\n",
    "model_results_files = [f for f in os.listdir(intermediate_path) if f.endswith(\"_multiclass_results.csv\")]\n",
    "\n",
    "# Создаем итоговый DataFrame для всех моделей\n",
    "final_results = []\n",
    "\n",
    "# Процесс обработки каждого промежуточного файла модели\n",
    "for model_results_file in model_results_files:\n",
    "    # Чтение промежуточного CSV файла\n",
    "    df = pd.read_csv(os.path.join(intermediate_path, model_results_file))\n",
    "    # display(df)\n",
    "\n",
    "    # Получаем список метрик, исключая \"Packet Size\" и \"Model\"\n",
    "    metrics_columns = [col for col in df.columns if col not in ['Packet Size', 'Model', 'File']]\n",
    "\n",
    "    # Определение лучшей выборки для каждой метрики\n",
    "    best = {}\n",
    "    counts = {}\n",
    "\n",
    "    # Добавление столбца Counts для каждой выборки\n",
    "    max1_counts_column = []\n",
    "    for index, row in df.iterrows():\n",
    "        max1_count = sum(1 for col in metrics_columns if row[col] == df[col].max())  # Считаем, сколько раз максимальное значение встречается\n",
    "        max1_counts_column.append(max1_count)\n",
    "\n",
    "    df[\"max 1\"] = max1_counts_column\n",
    "\n",
    "    # Для каждой метрики находим наилучшие выборки\n",
    "    for col in metrics_columns:  # Перебираем только метрики\n",
    "        max_value = df[col].max()  # Находим максимальное значение для метрики\n",
    "        best[col] = df[df[col] == max_value][\"Packet Size\"].tolist()  # Сохраняем размеры выборок с максимальным значением\n",
    "\n",
    "        # Подсчитаем, сколько раз каждая выборка была максимальной для этой метрики\n",
    "        counts[col] = df[col].value_counts().get(max_value, 0)  # Подсчитаем сколько раз максимальное значение встречается\n",
    "\n",
    "    # Строка Best\n",
    "    best_row = {\"Packet Size\": \"Best\"}\n",
    "    for col in metrics_columns:\n",
    "        best_row[col] = best[col]  # Присваиваем лучшие выборки для каждой метрики\n",
    "\n",
    "    # Добавление строки Best в DataFrame\n",
    "    df_best = pd.DataFrame([best_row])\n",
    "\n",
    "    # Добавление строки Best в DataFrame\n",
    "    df = pd.concat([df, df_best], ignore_index=True)\n",
    "    \n",
    "    model_results_file_modified = os.path.join(\n",
    "            intermediate_path_modified, f\"{os.path.splitext(model_results_file)[0]}_modified.csv\"\n",
    "        )\n",
    "\n",
    "    # Запись результатов в новый CSV файл\n",
    "    df.to_csv(model_results_file_modified, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
