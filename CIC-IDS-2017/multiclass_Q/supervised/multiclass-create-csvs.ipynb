{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brute-http': 1,\n",
       " 'brute-ftp': 2,\n",
       " 'inf-usb': 3,\n",
       " 'xss': 4,\n",
       " 'brute-ssh': 5,\n",
       " 'inf-dropbox': 6,\n",
       " 'sql-inj': 7,\n",
       " 'botnet-ares': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Путь к папке с атаками\n",
    "base_path = \"../attacks/\"\n",
    "\n",
    "combined_path = \"./combined_csvs/\"\n",
    "os.makedirs(combined_path, exist_ok=True)\n",
    "\n",
    "attack_folders = os.listdir(base_path)\n",
    "attack_labels = {attack: idx + 1 for idx, attack in enumerate(attack_folders)}\n",
    "attack_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найденные размеры выборок пакетов: [10, 50, 100, 250, 500, 750, 1000, 5000, 10000]\n"
     ]
    }
   ],
   "source": [
    "# Найти все уникальные размеры выборок\n",
    "packet_intervals = set()\n",
    "\n",
    "for attack in attack_folders:\n",
    "    common_path = os.path.join(base_path, attack, \"csvs\")\n",
    "    for traffic_type in [\"normal\", \"attack\"]:\n",
    "        traffic_path = os.path.join(common_path, traffic_type)\n",
    "        for filename in os.listdir(traffic_path):\n",
    "            # Извлечение размера выборки из имени файла с помощью регулярного выражения\n",
    "            match = re.search(r\"_(\\d+)_\\d+_\", filename)\n",
    "            if match:\n",
    "                packet_intervals.add(int(match.group(1)))\n",
    "\n",
    "# Сортируем размеры выборок\n",
    "packet_intervals = sorted(packet_intervals)\n",
    "print(\"Найденные размеры выборок пакетов:\", packet_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединение данных для каждого размера выборки\n",
    "for packet_size in packet_intervals:\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for attack in attack_folders:\n",
    "        attack_path = os.path.join(base_path, attack, \"csvs\")\n",
    "\n",
    "        # Определяем единственный файл нормального и атакующего трафика для текущего размера выборки\n",
    "        normal_file = next(\n",
    "            (\n",
    "                f\n",
    "                for f in os.listdir(os.path.join(attack_path, \"normal\"))\n",
    "                if f\"_{packet_size}_0_\" in f\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "        attack_file = next(\n",
    "            (\n",
    "                f\n",
    "                for f in os.listdir(os.path.join(attack_path, \"attack\"))\n",
    "                if f\"_{packet_size}_1_\" in f\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        if normal_file and attack_file:\n",
    "            # Чтение файла с нормальным трафиком и добавление метки\n",
    "            normal_df = pd.read_csv(os.path.join(attack_path, \"normal\", normal_file))\n",
    "            normal_df[\"Label\"] = 0  # Метка для нормального трафика\n",
    "            combined_df = pd.concat([combined_df, normal_df], ignore_index=True)\n",
    "\n",
    "            # Чтение файла с атакующим трафиком и добавление метки\n",
    "            attack_df = pd.read_csv(os.path.join(attack_path, \"attack\", attack_file))\n",
    "            attack_df[\"Label\"] = attack_labels[attack]  # Уникальная метка для атаки\n",
    "            combined_df = pd.concat([combined_df, attack_df], ignore_index=True)\n",
    "\n",
    "    # Сохранение объединенного CSV для текущего размера выборки\n",
    "    combined_file = os.path.join(combined_path, f\"combined_{packet_size}_packets.csv\")\n",
    "    combined_df.to_csv(combined_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2-12",
   "language": "python",
   "name": "tf-2-12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
